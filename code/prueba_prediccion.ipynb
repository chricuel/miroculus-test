{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de categorías\n",
    "## Christian Cuéllar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan modelos que identifican y aprenden patrones a partir de un conjunto de variables que, se asume, se relacionan con una etiqueta. La finalidad de implementar estos modelos es la de generar la mejor predicción para aquellas observaciones cuya etiqueta sea desconocida. Los modelos implementados son: regresión logística y SVMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesta y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lectura de los datos y separación entre datos etiquetados y no etiquetados\n",
    "df = pd.read_csv(\"/home/christian/Documents/Miroculus/test/miroculus-test/data/Miroculus.test.csv\", header = None)\n",
    "etiquetados = df[df[0] != '?']\n",
    "no_etiquetados = df[df[0] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Restamos un uno a la etiqueta para que el rango tome los valores 0/1 (en lugar de 1/2)\n",
    "etiquetados['etiqueta'] = etiquetados.loc[:,0].map(lambda x: 1 if x == \"2\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dividimos en conjuntos de entrenamiento y prueba\n",
    "X = etiquetados.ix[:, 1:14]\n",
    "y = etiquetados['etiqueta']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Escalamos los datos de entrenamiento\n",
    "from sklearn import preprocessing\n",
    "scaleX = preprocessing.StandardScaler()\n",
    "\n",
    "scaleX.fit(X_train)\n",
    "X_train = scaleX.transform(X_train)\n",
    "X_test = scaleX.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuevamente los datos en conjuntos de validacion y de prueba para seleccionar los mejores parámetros de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_prueba, X_valida, Y_prueba, Y_valida = train_test_split(X_train, Y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selección de la constante de regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Precision conjunto de prueba</th>\n",
       "      <th>Precision conjunto de validación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lambda  Precision conjunto de prueba  Precision conjunto de validación\n",
       "0     0.1                        0.8375                          0.761905\n",
       "1     0.2                        0.8625                          0.904762\n",
       "2     0.3                        0.9000                          0.904762\n",
       "3     0.4                        0.9000                          0.904762\n",
       "4     0.5                        0.9125                          0.857143\n",
       "5     0.6                        0.9125                          0.857143\n",
       "6     0.7                        0.9125                          0.857143\n",
       "7     0.8                        0.9125                          0.809524\n",
       "8     0.9                        0.9125                          0.809524"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = np.arange(0.1,1,0.1)\n",
    "\n",
    "lam_i = []\n",
    "precision_prueba_l = []\n",
    "precision_validacion_l = []\n",
    "\n",
    "for x in range(len(lam)):\n",
    "    reglog_l = LogisticRegression(C=lam[x], penalty='l1', tol=0.01)\n",
    "    reglog_l.fit(X_prueba, Y_prueba)\n",
    "    y_pred_log_train_l = reglog_l.score(X_prueba, Y_prueba)\n",
    "    y_pred_log_test_l = reglog_l.score(X_valida, Y_valida)\n",
    "    \n",
    "    lam_i.append(lam[x])\n",
    "    precision_prueba_l.append(y_pred_log_train_l)\n",
    "    precision_validacion_l.append(y_pred_log_test_l)\n",
    "    \n",
    "precision_lambda = pd.DataFrame({'Lambda' : lam_i, 'Precision conjunto de prueba' : precision_prueba_l,\n",
    "                                 'Precision conjunto de validación':precision_validacion_l })\n",
    "precision_lambda\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme aumenta el valor de la Lambda, la precisión en el conjunto de validación empeora. Se selecciona Lambda = 0.4, porque con este valor se maximiza la precisión en el conjunto de validación (y tiene una de las mejores precisiones para el conjunto de prueba)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modelo de regresión logística con la constante óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de entrenamiento 0.910891089109\n",
      "Prediccion en el conjunto de prueba: 0.823529411765\n"
     ]
    }
   ],
   "source": [
    "reglog = LogisticRegression(C=0.4, penalty='l1', tol=0.01)\n",
    "reglog.fit(X_train, Y_train)\n",
    "\n",
    "# Para calcular la precisión media que se reporta abajo\n",
    "y_pred_log_train = reglog.score(X_train, Y_train)\n",
    "y_pred_log_test = reglog.score(X_test, Y_test)\n",
    "\n",
    "# Etiqueta predicha:\n",
    "y_predict_ltest = reglog.predict(X_test)\n",
    "\n",
    "# Probabilidad de pertenecer a cada clase:\n",
    "y_pred_prob_ltes = reglog.predict_proba(X_test)\n",
    "y_pred_prob_ltes2 = np.asarray(pd.DataFrame(y_pred_prob_ltes)[[1]])\n",
    "\n",
    "print \"Precisión en el conjunto de entrenamiento\", y_pred_log_train\n",
    "print \"Prediccion en el conjunto de prueba:\", y_pred_log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  3],\n",
       "       [ 3, 14]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión para el test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test,y_predict_ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selección del parámetro de regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Precision conjunto de prueba</th>\n",
       "      <th>Precision conjunto de validación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lambda  Precision conjunto de prueba  Precision conjunto de validación\n",
       "0    0.01                        0.8875                          0.857143\n",
       "1    0.06                        0.8875                          0.904762\n",
       "2    0.11                        0.8875                          0.857143\n",
       "3    0.16                        0.9000                          0.857143\n",
       "4    0.21                        0.8875                          0.809524\n",
       "5    0.26                        0.8875                          0.809524\n",
       "6    0.31                        0.8875                          0.809524\n",
       "7    0.36                        0.9000                          0.809524\n",
       "8    0.41                        0.9125                          0.809524\n",
       "9    0.46                        0.9000                          0.809524"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam_svm = np.arange(0.01,0.5,0.05)\n",
    "lam_j = []\n",
    "precision_prueba_svm = []\n",
    "precision_validacion_svm = []\n",
    "\n",
    "for x in range(len(lam_svm)):\n",
    "    svm_l = SVC(C=lam_svm[x], kernel='linear', probability= True)\n",
    "    svm_l.fit(X_prueba, Y_prueba)\n",
    "    y_pred_svm_train_l = svm_l.score(X_prueba, Y_prueba)\n",
    "    y_pred_svm_test_l = svm_l.score(X_valida, Y_valida)\n",
    "    \n",
    "    lam_j.append(lam_svm[x])\n",
    "    precision_prueba_svm.append(y_pred_svm_train_l)\n",
    "    precision_validacion_svm.append(y_pred_svm_test_l)\n",
    "#   print \"Lambda =\", lam[x], \" Precisión en el conjunto de prueba:\",  y_pred_log_train_l\n",
    "#   print \"Lambda =\", lam[x], \" Precisión en el conjunto de validación:\", y_pred_log_test_l\n",
    "    \n",
    "precision_lambda_svm = pd.DataFrame({'Lambda' : lam_j, 'Precision conjunto de prueba' : precision_prueba_svm,\n",
    "                                 'Precision conjunto de validación':precision_validacion_svm })\n",
    "precision_lambda_svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elige Lambda = 0.06 porque es el valor que maximiza la precisión en el conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo SVM con el parámetro de penalización óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.06, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_t = SVC(C=0.06, kernel='linear', probability= True)\n",
    "svm_t.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción en el conjunto de entrenamiento 0.891089108911\n",
      "Predicción el conjunto de prueba 0.852941176471\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades predichas para el conjunto de prueba\n",
    "Y_predict_t =  svm_t.predict_proba(X_test)\n",
    "y_pred_prob_svmt = np.asarray(pd.DataFrame(Y_predict_t)[[1]])\n",
    "\n",
    "# Precisión en ambos conjuntos\n",
    "svmt_score = svm_t.score(X_train, Y_train)\n",
    "svmt_score2 = svm_t.score(X_test, Y_test)\n",
    "\n",
    "print \"Predicción en el conjunto de entrenamiento\", svmt_score\n",
    "print \"Predicción el conjunto de prueba\", svmt_score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión en el conjunto de entrenamiento es igual que en el caso con Logit, mientras que la precisión del conjunto de entrenamiento es peor para SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA y Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probó reducir la dimensionalidad utilizando las primeras tres componentes principales de los datos. Las variables transformadas se utilizaron en un modelo Logit sin constante de regularización para ver si mejoraba la predicción. Los resultados se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24193438  0.13312597  0.09603896]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Varianza explicada\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "pca_data_train = pd.DataFrame(pca.fit_transform(X_train), columns=['primera','segunda', 'tercera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aplicar componentes principales para el test set (utilizando los resultados del train set)\n",
    "pca_data_test = pd.DataFrame(pca.transform(X_test), columns=['primera','segunda', 'tercera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción en el train 0.851485148515\n",
      "Prediccion en el test: 0.823529411765\n"
     ]
    }
   ],
   "source": [
    "reglog_pca = LogisticRegression(C=1, penalty='l1', tol=0.01)\n",
    "reglog_pca.fit(pca_data_train, Y_train)\n",
    "\n",
    "# Para calcular la precisión media que se reporta abajo\n",
    "y_pred_log_train_pca = reglog_pca.score(pca_data_train, Y_train)\n",
    "y_pred_log_test_pca = reglog_pca.score(pca_data_test, Y_test)\n",
    "\n",
    "# Etiqueta predicha:\n",
    "y_predict_ltest_pca = reglog_pca.predict(pca_data_test)\n",
    "\n",
    "# Probabilidad de pertenecer a cada clase:\n",
    "y_pred_prob_ltes_pca = reglog_pca.predict_proba(pca_data_test)\n",
    "y_pred_prob_ltes2_pca = np.asarray(pd.DataFrame(y_pred_prob_ltes_pca)[[1]])\n",
    "\n",
    "print \"Predicción en el train\", y_pred_log_train_pca\n",
    "print \"Prediccion en el test:\", y_pred_log_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que todos los modelos fueron relativamente buenos. Se elige el modelo de regresión logística con Lambda = 0.4 como el mejor porque indica la mejor precisión tanto para el conjunto de entrenamiento como para el de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos la precisión promedio con base en la selección del mejor modelo para ver que tan robusto es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X.as_matrix()\n",
    "y1 = y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 0  Precisión en el conjunto de prueba: 0.785714285714\n",
      "K = 1  Precisión en el conjunto de prueba: 0.785714285714\n",
      "K = 2  Precisión en el conjunto de prueba: 0.928571428571\n",
      "K = 3  Precisión en el conjunto de prueba: 0.857142857143\n",
      "K = 4  Precisión en el conjunto de prueba: 0.928571428571\n",
      "K = 5  Precisión en el conjunto de prueba: 0.923076923077\n",
      "K = 6  Precisión en el conjunto de prueba: 0.923076923077\n",
      "K = 7  Precisión en el conjunto de prueba: 0.846153846154\n",
      "K = 8  Precisión en el conjunto de prueba: 0.923076923077\n",
      "K = 9  Precisión en el conjunto de prueba: 0.769230769231\n",
      "Precisión promedio: 0.867032967033\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "logit = LogisticRegression(C=0.4, penalty='l1', tol=0.01)\n",
    "k_fold = cross_validation.KFold(len(X1), n_folds=10)\n",
    "\n",
    "precision_vc = []\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold):\n",
    "    logit.fit(X1[train], y1[train])\n",
    "    z = logit.score(X1[test], y1[test])\n",
    "    precision_vc.append(z)\n",
    "    print \"K =\", k, \" Precisión en el conjunto de prueba:\",  z\n",
    "\n",
    "print \"Precisión promedio:\", sum(precision_vc)/len(precision_vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta que el modelo seleccionado es suficientemente bueno para categorizar las observaciones con independencia de los datos observados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción para las observaciones sin etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se generaran las predicciones para las observaciones en las que no se tiene información de la etiqueta. Se presentan tanto la probabilidad de pertenencia a una categoría, como la etiqueta predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_n = no_etiquetados.ix[:,1:14]\n",
    "X_matrix = X_n.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Etiqueta predicha:\n",
    "prediccion_etiqueta = reglog.predict(X_matrix)\n",
    "\n",
    "# Probabilidad de pertenecer a cada clase:\n",
    "proba_etiqueta = reglog.predict_proba(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_etiquetados['etiqueta_predicha'] = prediccion_etiqueta.tolist()\n",
    "no_etiquetados['proba_etiqueta_0'] = proba_etiqueta[:,0].tolist()\n",
    "no_etiquetados['proba_etiqueta_1'] = proba_etiqueta[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_etiquetados.to_csv('/home/christian/Documents/Miroculus/test/miroculus-test/predictions/prediccion_no_etiquetados.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones para todas las observaciones con las etiquetas originales (1 y 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso, sólo se hace la predicción para todas las observaciones utilizando la base de datos original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "todas = df.ix[:,1:14].as_matrix()\n",
    "\n",
    "# Etiqueta predicha:\n",
    "prediccion_etiqueta_todas = reglog.predict(todas)\n",
    "\n",
    "# Probabilidad de pertenecer a cada clase:\n",
    "proba_etiqueta_todas = reglog.predict_proba(todas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediccion_etiqueta_todas = prediccion_etiqueta_todas +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['etiqueta_predicha'] = prediccion_etiqueta_todas.tolist()\n",
    "df['proba_etiqueta_1'] = proba_etiqueta_todas[:,0].tolist()\n",
    "df['proba_etiqueta_2'] = proba_etiqueta_todas[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('/home/christian/Documents/Miroculus/test/miroculus-test/predictions/prediccion_todas.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
